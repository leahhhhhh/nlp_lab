{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAGE1 COMPARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./jili7206_group168-stage1.txt', 'r') as file:\n",
    "    jw_content = file.readlines()\n",
    "\n",
    "with open('./group168-stage1.txt.provided-anno.txt', 'r') as file:\n",
    "    stage1_content = file.readlines()\n",
    "\n",
    "with open('./czha5286-group168-stage1.txt', 'r') as file:\n",
    "    cz_content = file.readlines()\n",
    "# 清除每行中的换行符并创建列表\n",
    "jw_content = [line.strip() for line in jw_content]\n",
    "stage1_content = [line.strip() for line in stage1_content]\n",
    "cz_content = [line.strip() for line in cz_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class F1_score_evaluation():\n",
    "    def __init__(self,provide_text,compare_text,should_convert=False) -> None:\n",
    "        self.provide_text=provide_text\n",
    "        self.compare_text=compare_text\n",
    "        self.should_convert=should_convert\n",
    "\n",
    "    def __call__(self):\n",
    "        provide_converted = self.convert_provide_text() if self.should_convert else self.provide_text\n",
    "        return self.evaluate(self.compare_text,provide_converted)\n",
    "\n",
    "    def replace_repeat_pos(self,string):\n",
    "        \"\"\" \n",
    "        convert the provide to slate format\n",
    "        \"\"\"\n",
    "        pattern = r\"\\(\\d+,\\s*\\d+\\)\"\n",
    "        matches = re.findall(pattern, string)\n",
    "        if(matches[0]==matches[1]):\n",
    "            string = string.replace(matches[0]+\", \",\"\",1)\n",
    "            string = string.replace(\"(\",\"\",1)\n",
    "            string = string.replace(\")\",\"\",1)\n",
    "        return string\n",
    "    \n",
    "    def convert_provide_text(self):\n",
    "        text_filter=[]\n",
    "        for i in self.provide_text:\n",
    "            convert=self.replace_repeat_pos(i)\n",
    "            text_filter.append(convert)\n",
    "        return text_filter\n",
    "    \n",
    "    def evaluate(self,predict,text_filter):\n",
    "        \"\"\" \n",
    "        predict: manual annotation file\n",
    "        text_filter: provided file\n",
    "        \"\"\"\n",
    "        TP=0\n",
    "        for item1 in predict:\n",
    "            for item2 in text_filter:\n",
    "                if item1==item2:\n",
    "                    TP+=1\n",
    "        FP=len(predict)-TP\n",
    "        FN=len(text_filter)-TP\n",
    "        precision=TP/(TP+FP)\n",
    "        recall=TP/(TP+FN)\n",
    "        F1_score=2 * (precision * recall) / (precision + recall)\n",
    "        return TP,FP,F1_score,FN\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1_score : jili7206 & stage1_provided_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 89 FP: 96 FN: 207 \n",
      "F1_score: 0.3700623700623701\n"
     ]
    }
   ],
   "source": [
    "evaluate = F1_score_evaluation(stage1_content,jw_content,should_convert=True) # Initialization\n",
    "TP,FP,F1_score,FN=evaluate() # The same as evaluate.__call__()\n",
    "print(f\"TP: {TP}\",f\"FP: {FP}\",f\"FN: {FN}\",f\"\\nF1_score: {F1_score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1_score : czha5286 & stage1_provided_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 179 FP: 169 FN: 117 \n",
      "F1_score: 0.5559006211180123\n"
     ]
    }
   ],
   "source": [
    "evaluate = F1_score_evaluation(stage1_content,cz_content,should_convert=True) # Initialization\n",
    "TP,FP,F1_score,FN=evaluate() # The same as evaluate.__call__()\n",
    "print(f\"TP: {TP}\",f\"FP: {FP}\",f\"FN: {FN}\",f\"\\nF1_score: {F1_score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1_score : jili7206 & czha5286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:156 FP:29 FN:192 \n",
      " F1_score:0.5853658536585366\n"
     ]
    }
   ],
   "source": [
    "evaluate = F1_score_evaluation(cz_content,jw_content) \n",
    "TP,FP,F1_score,FN=evaluate()\n",
    "print(f\"TP:{TP}\",f\"FP:{FP}\",f\"FN:{FN}\",f\"\\n F1_score:{F1_score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAGE 3 COMPARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../jili7206-group168-stage3.txt', 'r') as file:\n",
    "    jw_content_stage3 = file.readlines()\n",
    "\n",
    "with open('../group168-stage3.txt.provided-anno.txt', 'r') as file:\n",
    "    stage3_content = file.readlines()\n",
    "\n",
    "with open('../czha5286-group168-stage3.txt', 'r') as file:\n",
    "    cz_content_stage3 = file.readlines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1_score : jili7206 & stage3_provided_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 205 FP: 71 FN: 92 \n",
      "F1_score: 0.7155322862129143\n"
     ]
    }
   ],
   "source": [
    "evaluate = F1_score_evaluation(stage3_content,jw_content_stage3,should_convert=True) # Initialization\n",
    "TP,FP,F1_score,FN=evaluate() # The same as evaluate.__call__()\n",
    "print(f\"TP: {TP}\",f\"FP: {FP}\",f\"FN: {FN}\",f\"\\nF1_score: {F1_score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1_score : czha5286 & stage3_provided_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 205 FP: 81 FN: 92 \n",
      "F1_score: 0.7032590051457975\n"
     ]
    }
   ],
   "source": [
    "evaluate = F1_score_evaluation(stage3_content,cz_content_stage3,should_convert=True) # Initialization\n",
    "TP,FP,F1_score,FN=evaluate() # The same as evaluate.__call__()\n",
    "print(f\"TP: {TP}\",f\"FP: {FP}\",f\"FN: {FN}\",f\"\\nF1_score: {F1_score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1_score : jili7206 & czha5286 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 251 FP: 25 FN: 35 \n",
      "F1_score: 0.893238434163701\n"
     ]
    }
   ],
   "source": [
    "evaluate = F1_score_evaluation(cz_content_stage3,jw_content_stage3)\n",
    "TP,FP,F1_score,FN=evaluate() # The same as evaluate.__call__()\n",
    "print(f\"TP: {TP}\",f\"FP: {FP}\",f\"FN: {FN}\",f\"\\nF1_score: {F1_score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare flair&adjust_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./flair_group168-stage1.txt', 'r') as file:\n",
    "    flair = file.readlines()\n",
    "\n",
    "with open('./spacy-group168-stage1.txt', 'r') as file:\n",
    "    spacy = file.readlines()\n",
    "\n",
    "with open('./stanza-group168-stage1.txt', 'r') as file:\n",
    "    stanza = file.readlines()\n",
    "\n",
    "with open('./adjust_annotation_stage2_group168.txt', 'r') as file:\n",
    "    adjust_annotation_stage2 = file.readlines()\n",
    "# 清除每行中的换行符并创建列表\n",
    "flair = [line.strip() for line in flair]\n",
    "spacy = [line.strip() for line in spacy]\n",
    "stanza = [line.strip() for line in stanza]\n",
    "adjust_annotation_stage2=[line.strip() for line in adjust_annotation_stage2]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- f1 flair vs adjust_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "presicion:0.7714285714285715,\n",
      "recall:0.18305084745762712,\n",
      "f1-score:0.2958904109589041\n"
     ]
    }
   ],
   "source": [
    "# evaluate = F1_score_evaluation(flair,adjust_annotation_stage2,should_convert=True) # Initialization\n",
    "# TP,FP,F1_score,FN=evaluate() # The same as evaluate.__call__()\n",
    "# print(f\"TP: {TP}\",f\"FP: {FP}\",f\"FN: {FN}\",f\"\\nF1_score: {F1_score}\")\n",
    "\n",
    "def f1_cal(model,adjust):\n",
    "    tp=0\n",
    "    for i in model:\n",
    "        for j in adjust:\n",
    "            if i == j:\n",
    "                tp+=1\n",
    "    fp=len(model)-tp\n",
    "    fn=len(adjust)-tp\n",
    "    presision=tp/(tp+fp)\n",
    "    recall=tp/(tp+fn)\n",
    "    f1_score=2 * (precision * recall) / (precision + recall)\n",
    "    return presision,recall,f1_score\n",
    "precision,recall,f1_score=f1_cal(flair,adjust_annotation_stage2)\n",
    "print(f'presicion:{precision},\\nrecall:{recall},\\nf1-score:{f1_score}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- spacy f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "presicion:0.6486486486486487,\n",
      "recall:0.16271186440677965,\n",
      "f1-score:0.2687402799377916\n"
     ]
    }
   ],
   "source": [
    "precision,recall,f1_score=f1_cal(spacy,adjust_annotation_stage2)\n",
    "print(f'presicion:{precision},\\nrecall:{recall},\\nf1-score:{f1_score}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- stanza f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "presicion:0.9090909090909091,\n",
      "recall:0.2033898305084746,\n",
      "f1-score:0.3096774193548387\n"
     ]
    }
   ],
   "source": [
    "precision,recall,f1_score=f1_cal(stanza,adjust_annotation_stage2)\n",
    "print(f'presicion:{precision},\\nrecall:{recall},\\nf1-score:{f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
